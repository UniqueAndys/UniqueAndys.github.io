<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 在Ubuntu下布置Hadoop单机伪分布式 · Andy's blog</title><meta name="description" content="在Ubuntu下布置Hadoop单机伪分布式 - Andy Song"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/u/2532176501" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/uniqueandys" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">在Ubuntu下布置Hadoop单机伪分布式</h1><div class="post-time">Oct 21, 2016</div><div class="post-content"><p>为了职业发展，开始试水大数据，今天带来一篇在Ubuntu14.04下布置Hadoop-2.7.1版本单机伪分布式的教程。<br><a id="more"></a></p>
<h1 id="1-安装和配置JDK"><a href="#1-安装和配置JDK" class="headerlink" title="1. 安装和配置JDK"></a>1. 安装和配置JDK</h1><p>在官网上下载JDK，解压并拷贝到<code>/usr/local</code>下。接下来配置环境变量，打开<code>/etc/profile</code>并添加<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.<span class="number">8.0</span>_101</span><br><span class="line">PATH=<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME PATH CLASSPATH</span><br></pre></td></tr></table></figure></p>
<p>保存退出，一般执行<code>source /etc/profile</code>可以使配置立即生效，有时也需要重新打开terminal或者重启。<br>执行<code>java -version</code>和<code>$JAVA_HOME/bin/java -version</code>查看是否都会打印版本信息。</p>
<p><img src="/img/hadoop/java_version.png" alt=""></p>
<h1 id="2-下载安装Hadoop"><a href="#2-下载安装Hadoop" class="headerlink" title="2. 下载安装Hadoop"></a>2. 下载安装Hadoop</h1><p>从Apache Hadoop官网下载一个稳定的发布包，这里我们下载2.7.1版本，解压到本地文件系统中，推荐就放在用户主目录下。</p>
<h1 id="3-配置SSH"><a href="#3-配置SSH" class="headerlink" title="3. 配置SSH"></a>3. 配置SSH</h1><p>为了保证在远程管理Hadoop节点以及Hadoop节点间用户共享访问时的安全性，Hadoop系统需要配置和使用SSH（安全外壳协议）。这里配置SSH的主要工作是创建一个认证文件，使得用户以public key方式登陆，而不用手工输密码。配置的基本步骤如下：</p>
<ol>
<li>生成密钥对，执行命令<code>ssh-keygen -t rsa</code></li>
<li>一直按<code>Enter</code>键，默认生成的密钥对保存在<code>.ssh/id_rsa</code>文件中</li>
<li>进入<code>.ssh</code>目录，执行命令<code>cp id_rsa.pub authorized_keys</code></li>
<li>执行命令<code>ssh localhost</code>即可测试是否登陆。</li>
</ol>
<h1 id="4-配置Hadoop环境"><a href="#4-配置Hadoop环境" class="headerlink" title="4. 配置Hadoop环境"></a>4. 配置Hadoop环境</h1><p>Hadoop-2.7.1版本需要配置三个文件，位于Hadoop下<code>etc/hadoop</code>文件中，分别是Hadoop环境变量设置文件<code>hadoop-env.sh</code>，全局配置文件<code>core-site.xml</code>，HDFS配置文件<code>hdfs-site.xml</code>。</p>
<ol>
<li><p><code>hadoop-env.sh</code>配置文件，修改JAVA_HOME变量为jdk所在路径。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.<span class="number">8.0</span>_101</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>core-site.xml</code>配置文件，在configuration中添加内容。其中，hadoop.tmp.dir的value为hadoop所在的路径。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">value</span>&gt;</span>file:/home/tyrion/hadoop-2.7.1<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="title">description</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>hdfs-site.xml</code>配置文件，同样在configuration中添加内容。namenode和datanode的路径同样改为自己Hadoop所在的路径下。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">value</span>&gt;</span>1<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">value</span>&gt;</span>file:/home/tyrion/hadoop-2.7.1/tmp/dfs/name<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="title">value</span>&gt;</span>file:/home/tyrion/hadoop-2.7.1/tmp/dfs/data<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>伪分布式虽然只需要配置fs.defaultFS和dfs.replicaton就可以运行，不过若没有配置hadoop.tmp.dir参数，则默认使用的临时目录为/tmp/hadoop/username，而这个目录重启时可能被系统清理掉，导致必须重新执行format才行。</p>
</blockquote>
</li>
</ol>
<h1 id="5-Hadoop的运行"><a href="#5-Hadoop的运行" class="headerlink" title="5. Hadoop的运行"></a>5. Hadoop的运行</h1><ol>
<li><p>为方便在terminal中直接使用<code>hadoop</code>命令，在自己用户主目录下的<code>.bashrc</code>中添加环境变量。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/home/tyrion/hadoop-<span class="number">2.7</span>.<span class="number">1</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure>
<p> 同样使用命令<code>source .bashrc</code>使其立即生效，执行<code>hadoop version</code>查看是否显示Hadoop版本信息。<br><img src="/img/hadoop/hadoop_version.png" alt=""></p>
</li>
<li>在初次安装和使用Hadoop之前，需要格式化分布式文件系统HDFS，使用命令<code>hadoop namenode -format</code>。</li>
<li><p>在Hadoop目录下执行命令<code>./sbin/start-dfs.sh</code>启动Hadoop，启动之后使用<code>jps</code>命令查看启动的进程。<br><img src="/img/hadoop/start_dfs.png" alt=""></p>
</li>
<li><p>执行命令<code>./sbin/stop-dfs.sh</code>停止Hadoop守护进程。</p>
<blockquote>
<p>格式化命令只能在初次安装时使用，如果再次使用的话，namenode之前保存的datanode的信息会丢失，导致DataNode这个节点不会启动。解决办法是修改datanode文件夹中current下的VERSION文件，将其中的clusterID修改为namenode中对应的clusterID。</p>
</blockquote>
</li>
</ol>
<p>至此便大功告成啦，接下来我会实现一些简单的MapReduce基础算法程序，加油咯！</p>
</div></article></div></section><footer><div class="paginator"><a href="/2016/10/24/Hadoop-WordCount/" class="prev">上一篇</a><a href="/2016/05/03/badminton/" class="next">下一篇</a></div><div class="copyright"><p>© 2015 - 2016 <a href="http://songbinbin.me">Andy Song</a>, unless otherwise noted.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-65933410-1",'auto');ga('send','pageview');</script><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?a36e15d9e2adec9a21fcdd9f686b1ed2";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>